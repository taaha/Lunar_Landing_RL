{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing Dependencies","metadata":{}},{"cell_type":"code","source":"!apt install swig cmake","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-07-04T16:15:39.026656Z","iopub.execute_input":"2023-07-04T16:15:39.027041Z","iopub.status.idle":"2023-07-04T16:15:41.192103Z","shell.execute_reply.started":"2023-07-04T16:15:39.027011Z","shell.execute_reply":"2023-07-04T16:15:41.190950Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nswig is already the newest version (4.0.2-1ubuntu1).\ncmake is already the newest version (3.22.1-1ubuntu1.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 67 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install stable-baselines3 gymnasium[box2d] huggingface_sb3","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:15:41.194389Z","iopub.execute_input":"2023-07-04T16:15:41.195077Z","iopub.status.idle":"2023-07-04T16:16:39.032800Z","shell.execute_reply.started":"2023-07-04T16:15:41.195038Z","shell.execute_reply":"2023-07-04T16:16:39.031595Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting stable-baselines3\n  Using cached stable_baselines3-2.0.0-py3-none-any.whl (178 kB)\nRequirement already satisfied: gymnasium[box2d] in /opt/conda/lib/python3.10/site-packages (0.26.3)\nCollecting huggingface_sb3\n  Using cached huggingface_sb3-2.2.5-py3-none-any.whl (9.5 kB)\nCollecting gymnasium==0.28.1 (from stable-baselines3)\n  Using cached gymnasium-0.28.1-py3-none-any.whl (925 kB)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (1.23.5)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (2.0.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (2.2.1)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (1.5.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from stable-baselines3) (3.6.3)\nCollecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1->stable-baselines3)\n  Using cached jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\nRequirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from gymnasium==0.28.1->stable-baselines3) (4.5.0)\nCollecting farama-notifications>=0.0.1 (from gymnasium==0.28.1->stable-baselines3)\n  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\nINFO: pip is looking at multiple versions of gymnasium[box2d] to determine which version is compatible with other requirements. This could take a while.\nCollecting box2d-py==2.3.5 (from gymnasium==0.28.1->stable-baselines3)\n  Using cached box2d-py-2.3.5.tar.gz (374 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pygame==2.1.3 (from gymnasium==0.28.1->stable-baselines3)\n  Using cached pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\nCollecting swig==4.* (from gymnasium==0.28.1->stable-baselines3)\n  Using cached swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\nRequirement already satisfied: huggingface-hub~=0.8 in /opt/conda/lib/python3.10/site-packages (from huggingface_sb3) (0.15.1)\nCollecting pyyaml~=6.0 (from huggingface_sb3)\n  Using cached PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\nRequirement already satisfied: wasabi in /opt/conda/lib/python3.10/site-packages (from huggingface_sb3) (1.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3) (3.12.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3) (2023.6.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3) (2.28.2)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3) (4.64.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub~=0.8->huggingface_sb3) (21.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->stable-baselines3) (3.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (1.0.7)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (4.39.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (9.5.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->stable-baselines3) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->stable-baselines3) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->stable-baselines3) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11->stable-baselines3) (1.3.0)\nBuilding wheels for collected packages: box2d-py\n  Building wheel for box2d-py (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=494937 sha256=fb84829bc6ac3d00f93a8e41b5e0bf4b909aab6ee62bb62d9dfdf3d640ee6584\n  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\nSuccessfully built box2d-py\nInstalling collected packages: swig, farama-notifications, box2d-py, pyyaml, pygame, jax-jumpy, gymnasium, stable-baselines3, huggingface_sb3\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 5.4.1\n    Uninstalling PyYAML-5.4.1:\n      Successfully uninstalled PyYAML-5.4.1\n  Attempting uninstall: gymnasium\n    Found existing installation: Gymnasium 0.26.3\n    Uninstalling Gymnasium-0.26.3:\n      Successfully uninstalled Gymnasium-0.26.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 23.6.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cuda 23.6.0 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\ndask-cudf 23.6.0 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\ndistributed 2023.3.2.1 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\njupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 1.8.21 requires google-api-python-client<2,>=1.7.8, but you have google-api-python-client 2.88.0 which is incompatible.\nkfp 1.8.21 requires PyYAML<6,>=5.3, but you have pyyaml 6.0 which is incompatible.\nraft-dask 23.6.1 requires dask==2023.3.2, but you have dask 2023.6.0 which is incompatible.\nydata-profiling 4.1.2 requires scipy<1.10,>=1.4.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed box2d-py-2.3.5 farama-notifications-0.0.4 gymnasium-0.28.1 huggingface_sb3-2.2.5 jax-jumpy-1.0.0 pygame-2.1.3 pyyaml-6.0 stable-baselines3-2.0.0 swig-4.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!sudo apt-get update\n!apt install python-opengl\n!apt install ffmpeg\n!apt install xvfb\n!pip3 install pyvirtualdisplay","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:16:39.036190Z","iopub.execute_input":"2023-07-04T16:16:39.037071Z","iopub.status.idle":"2023-07-04T16:17:00.841973Z","shell.execute_reply.started":"2023-07-04T16:16:39.037024Z","shell.execute_reply":"2023-07-04T16:17:00.840781Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Get:1 http://packages.cloud.google.com/apt gcsfuse-focal InRelease [5002 B]\nGet:2 https://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]       \nGet:3 https://packages.cloud.google.com/apt google-fast-socket InRelease [5015 B]\nGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]      \nHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1581 B]\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]        \nGet:8 http://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [2356 B]\nGet:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [108 kB]\nGet:10 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [474 kB]\nGet:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [410 kB]\nGet:12 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [43.2 kB]\nGet:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [944 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [978 kB]\nGet:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [684 kB]\nGet:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [633 kB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [674 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.0 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1197 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [25.5 kB]\nFetched 6471 kB in 1s (5071 kB/s)                       \nReading package lists... Done\nW: http://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\nW: https://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\n\u001b[1;31mE: \u001b[0mUnable to locate package python-opengl\u001b[0m\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nxvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 84 not upgraded.\nCollecting pyvirtualdisplay\n  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\nInstalling collected packages: pyvirtualdisplay\nSuccessfully installed pyvirtualdisplay-3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install moviepy","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:19:05.458419Z","iopub.execute_input":"2023-07-04T17:19:05.458932Z","iopub.status.idle":"2023-07-04T17:19:31.684607Z","shell.execute_reply.started":"2023-07-04T17:19:05.458898Z","shell.execute_reply":"2023-07-04T17:19:31.683202Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Collecting moviepy\n  Downloading moviepy-1.0.3.tar.gz (388 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n  Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\nRequirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.10/site-packages (from moviepy) (4.64.1)\nRequirement already satisfied: requests<3.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.28.2)\nCollecting proglog<=1.0.0 (from moviepy)\n  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from moviepy) (1.23.5)\nRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.10/site-packages (from moviepy) (2.28.1)\nCollecting imageio_ffmpeg>=0.2.0 (from moviepy)\n  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.5.7)\nBuilding wheels for collected packages: moviepy\n  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110744 sha256=a45cf58a52836a2cd6d0a406c68bbae252cd1996ac872a134b101cabcc69489e\n  Stored in directory: /root/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\nSuccessfully built moviepy\nInstalling collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.1.1\n    Uninstalling decorator-5.1.1:\n      Successfully uninstalled decorator-5.1.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2023.5.0 requires fsspec==2023.5.0, but you have fsspec 2023.6.0 which is incompatible.\njupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.8 moviepy-1.0.3 proglog-0.1.10\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Restarting run-time\nimport os\nos.kill(os.getpid(), 9)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Virtual display\nfrom pyvirtualdisplay import Display\n\nvirtual_display = Display(visible=0, size=(1400, 900))\nvirtual_display.start()","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:17:24.953496Z","iopub.execute_input":"2023-07-04T16:17:24.953940Z","iopub.status.idle":"2023-07-04T16:17:25.593551Z","shell.execute_reply.started":"2023-07-04T16:17:24.953902Z","shell.execute_reply":"2023-07-04T16:17:25.592578Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<pyvirtualdisplay.display.Display at 0x7aa4c303a260>"},"metadata":{}}]},{"cell_type":"code","source":"import gymnasium\n\nfrom huggingface_sb3 import load_from_hub, package_to_hub\nfrom huggingface_hub import notebook_login # To log to our Hugging Face account to be able to upload models to the Hub.\n\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.evaluation import evaluate_policy\nfrom stable_baselines3.common.monitor import Monitor","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:17:30.968876Z","iopub.execute_input":"2023-07-04T16:17:30.969275Z","iopub.status.idle":"2023-07-04T16:17:43.170173Z","shell.execute_reply.started":"2023-07-04T16:17:30.969243Z","shell.execute_reply":"2023-07-04T16:17:43.166681Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Creating and exploring environment","metadata":{}},{"cell_type":"code","source":"import gymnasium as gym\n\n# First, we create our environment called LunarLander-v2\nenv = gym.make(\"LunarLander-v2\")\n\n# Then we reset this environment\nobservation, info = env.reset()\n\nfor _ in range(20):\n  # Take a random action\n  action = env.action_space.sample()\n  print(\"Action taken:\", action)\n\n  # Do this action in the environment and get\n  # next_state, reward, terminated, truncated and info\n  observation, reward, terminated, truncated, info = env.step(action)\n  \n  # If the game is terminated (in our case we land, crashed) or truncated (timeout)\n  if terminated or truncated:\n      # Reset the environment\n      print(\"Environment is reset\")\n      observation, info = env.reset()\n\nenv.close()","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:18:05.931291Z","iopub.execute_input":"2023-07-04T16:18:05.932094Z","iopub.status.idle":"2023-07-04T16:18:06.004341Z","shell.execute_reply.started":"2023-07-04T16:18:05.932057Z","shell.execute_reply":"2023-07-04T16:18:06.003227Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Action taken: 3\nAction taken: 0\nAction taken: 2\nAction taken: 3\nAction taken: 0\nAction taken: 0\nAction taken: 0\nAction taken: 0\nAction taken: 2\nAction taken: 3\nAction taken: 2\nAction taken: 2\nAction taken: 0\nAction taken: 2\nAction taken: 2\nAction taken: 1\nAction taken: 1\nAction taken: 0\nAction taken: 0\nAction taken: 1\n","output_type":"stream"}]},{"cell_type":"code","source":"# We create our environment with gym.make(\"<name_of_the_environment>\")\nenv = gym.make(\"LunarLander-v2\")\nenv.reset()\nprint(\"_____OBSERVATION SPACE_____ \\n\")\nprint(\"Observation Space Shape\", env.observation_space.shape)\nprint(\"Sample observation\", env.observation_space.sample()) # Get a random observation","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:18:07.149604Z","iopub.execute_input":"2023-07-04T16:18:07.150303Z","iopub.status.idle":"2023-07-04T16:18:07.160252Z","shell.execute_reply.started":"2023-07-04T16:18:07.150267Z","shell.execute_reply":"2023-07-04T16:18:07.158814Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"_____OBSERVATION SPACE_____ \n\nObservation Space Shape (8,)\nSample observation [-69.89895   -70.00578    -3.691819   -3.9531987   2.1009874  -1.7691917\n   0.8955927   0.9867464]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"\\n _____ACTION SPACE_____ \\n\")\nprint(\"Action Space Shape\", env.action_space.n)\nprint(\"Action Space Sample\", env.action_space.sample()) # Take a random action","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:18:08.475942Z","iopub.execute_input":"2023-07-04T16:18:08.476310Z","iopub.status.idle":"2023-07-04T16:18:08.485407Z","shell.execute_reply.started":"2023-07-04T16:18:08.476280Z","shell.execute_reply":"2023-07-04T16:18:08.484190Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\n _____ACTION SPACE_____ \n\nAction Space Shape 4\nAction Space Sample 1\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create the vectorised environment of 16 environement\nenv = make_vec_env('LunarLander-v2', n_envs=16)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:18:09.404132Z","iopub.execute_input":"2023-07-04T16:18:09.404511Z","iopub.status.idle":"2023-07-04T16:18:09.425025Z","shell.execute_reply.started":"2023-07-04T16:18:09.404481Z","shell.execute_reply":"2023-07-04T16:18:09.423743Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Creating model","metadata":{}},{"cell_type":"code","source":"model = PPO(\n    policy = 'MlpPolicy',\n    env = env,\n    n_steps = 1024,\n    batch_size = 64,\n    n_epochs = 4,\n    gamma = 0.999,\n    gae_lambda = 0.98,\n    ent_coef = 0.01,\n    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:18:14.560874Z","iopub.execute_input":"2023-07-04T16:18:14.561256Z","iopub.status.idle":"2023-07-04T16:18:20.195499Z","shell.execute_reply.started":"2023-07-04T16:18:14.561226Z","shell.execute_reply":"2023-07-04T16:18:20.194475Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Train it for 1,000,000 timesteps\nmodel.learn(total_timesteps=1000000)\n# Save the model\nmodel_name = \"ppo-LunarLander-v2\"\nmodel.save(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-07-04T16:18:21.687247Z","iopub.execute_input":"2023-07-04T16:18:21.687654Z","iopub.status.idle":"2023-07-04T16:39:18.151714Z","shell.execute_reply.started":"2023-07-04T16:18:21.687622Z","shell.execute_reply":"2023-07-04T16:39:18.150515Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 92.6     |\n|    ep_rew_mean     | -194     |\n| time/              |          |\n|    fps             | 2092     |\n|    iterations      | 1        |\n|    time_elapsed    | 7        |\n|    total_timesteps | 16384    |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 93.6        |\n|    ep_rew_mean          | -144        |\n| time/                   |             |\n|    fps                  | 1906        |\n|    iterations           | 2           |\n|    time_elapsed         | 17          |\n|    total_timesteps      | 32768       |\n| train/                  |             |\n|    approx_kl            | 0.008312184 |\n|    clip_fraction        | 0.0747      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.00117     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.01e+03    |\n|    n_updates            | 4           |\n|    policy_gradient_loss | -0.00752    |\n|    value_loss           | 5.5e+03     |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 93           |\n|    ep_rew_mean          | -126         |\n| time/                   |              |\n|    fps                  | 1844         |\n|    iterations           | 3            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 0.0048260097 |\n|    clip_fraction        | 0.0255       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.37        |\n|    explained_variance   | -0.00456     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.23e+03     |\n|    n_updates            | 8            |\n|    policy_gradient_loss | -0.00381     |\n|    value_loss           | 1.9e+03      |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 92           |\n|    ep_rew_mean          | -124         |\n| time/                   |              |\n|    fps                  | 1812         |\n|    iterations           | 4            |\n|    time_elapsed         | 36           |\n|    total_timesteps      | 65536        |\n| train/                  |              |\n|    approx_kl            | 0.0066315336 |\n|    clip_fraction        | 0.0522       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.36        |\n|    explained_variance   | -0.00199     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 433          |\n|    n_updates            | 12           |\n|    policy_gradient_loss | -0.0043      |\n|    value_loss           | 1.07e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 88.4         |\n|    ep_rew_mean          | -109         |\n| time/                   |              |\n|    fps                  | 1785         |\n|    iterations           | 5            |\n|    time_elapsed         | 45           |\n|    total_timesteps      | 81920        |\n| train/                  |              |\n|    approx_kl            | 0.0056356704 |\n|    clip_fraction        | 0.0317       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.36        |\n|    explained_variance   | -0.000647    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 726          |\n|    n_updates            | 16           |\n|    policy_gradient_loss | -0.00236     |\n|    value_loss           | 907          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 91.5        |\n|    ep_rew_mean          | -90.6       |\n| time/                   |             |\n|    fps                  | 1773        |\n|    iterations           | 6           |\n|    time_elapsed         | 55          |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.010532724 |\n|    clip_fraction        | 0.0844      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.34       |\n|    explained_variance   | -0.000422   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 248         |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00514    |\n|    value_loss           | 603         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 94.7        |\n|    ep_rew_mean          | -73.5       |\n| time/                   |             |\n|    fps                  | 1759        |\n|    iterations           | 7           |\n|    time_elapsed         | 65          |\n|    total_timesteps      | 114688      |\n| train/                  |             |\n|    approx_kl            | 0.007636074 |\n|    clip_fraction        | 0.0918      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 1.85e-06    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 244         |\n|    n_updates            | 24          |\n|    policy_gradient_loss | -0.00669    |\n|    value_loss           | 471         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 98.3        |\n|    ep_rew_mean          | -63.6       |\n| time/                   |             |\n|    fps                  | 1726        |\n|    iterations           | 8           |\n|    time_elapsed         | 75          |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.008650315 |\n|    clip_fraction        | 0.0537      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.29       |\n|    explained_variance   | -5.61e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 272         |\n|    n_updates            | 28          |\n|    policy_gradient_loss | -0.00642    |\n|    value_loss           | 449         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 98.7         |\n|    ep_rew_mean          | -51.8        |\n| time/                   |              |\n|    fps                  | 1714         |\n|    iterations           | 9            |\n|    time_elapsed         | 86           |\n|    total_timesteps      | 147456       |\n| train/                  |              |\n|    approx_kl            | 0.0074340804 |\n|    clip_fraction        | 0.0464       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.28        |\n|    explained_variance   | 6.87e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 138          |\n|    n_updates            | 32           |\n|    policy_gradient_loss | -0.00427     |\n|    value_loss           | 352          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 102         |\n|    ep_rew_mean          | -41.1       |\n| time/                   |             |\n|    fps                  | 1707        |\n|    iterations           | 10          |\n|    time_elapsed         | 95          |\n|    total_timesteps      | 163840      |\n| train/                  |             |\n|    approx_kl            | 0.010665743 |\n|    clip_fraction        | 0.0854      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | -0.00121    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 184         |\n|    n_updates            | 36          |\n|    policy_gradient_loss | -0.00746    |\n|    value_loss           | 363         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 116         |\n|    ep_rew_mean          | -31         |\n| time/                   |             |\n|    fps                  | 1683        |\n|    iterations           | 11          |\n|    time_elapsed         | 107         |\n|    total_timesteps      | 180224      |\n| train/                  |             |\n|    approx_kl            | 0.009124746 |\n|    clip_fraction        | 0.0401      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | 9.79e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 238         |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.00385    |\n|    value_loss           | 405         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 114         |\n|    ep_rew_mean          | -24.5       |\n| time/                   |             |\n|    fps                  | 1674        |\n|    iterations           | 12          |\n|    time_elapsed         | 117         |\n|    total_timesteps      | 196608      |\n| train/                  |             |\n|    approx_kl            | 0.008073205 |\n|    clip_fraction        | 0.0524      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.19       |\n|    explained_variance   | 0.000795    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 233         |\n|    n_updates            | 44          |\n|    policy_gradient_loss | -0.00385    |\n|    value_loss           | 445         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 129         |\n|    ep_rew_mean          | -17.9       |\n| time/                   |             |\n|    fps                  | 1661        |\n|    iterations           | 13          |\n|    time_elapsed         | 128         |\n|    total_timesteps      | 212992      |\n| train/                  |             |\n|    approx_kl            | 0.007035611 |\n|    clip_fraction        | 0.0498      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.15       |\n|    explained_variance   | -0.0115     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 403         |\n|    n_updates            | 48          |\n|    policy_gradient_loss | -0.00298    |\n|    value_loss           | 678         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 164          |\n|    ep_rew_mean          | -9.56        |\n| time/                   |              |\n|    fps                  | 1609         |\n|    iterations           | 14           |\n|    time_elapsed         | 142          |\n|    total_timesteps      | 229376       |\n| train/                  |              |\n|    approx_kl            | 0.0058698663 |\n|    clip_fraction        | 0.0467       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.14        |\n|    explained_variance   | 1.55e-06     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 316          |\n|    n_updates            | 52           |\n|    policy_gradient_loss | -0.00327     |\n|    value_loss           | 679          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 203          |\n|    ep_rew_mean          | -14.9        |\n| time/                   |              |\n|    fps                  | 1562         |\n|    iterations           | 15           |\n|    time_elapsed         | 157          |\n|    total_timesteps      | 245760       |\n| train/                  |              |\n|    approx_kl            | 0.0045423782 |\n|    clip_fraction        | 0.0255       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.13        |\n|    explained_variance   | 6.31e-05     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 279          |\n|    n_updates            | 56           |\n|    policy_gradient_loss | 8.85e-05     |\n|    value_loss           | 684          |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 233        |\n|    ep_rew_mean          | -3.5       |\n| time/                   |            |\n|    fps                  | 1487       |\n|    iterations           | 16         |\n|    time_elapsed         | 176        |\n|    total_timesteps      | 262144     |\n| train/                  |            |\n|    approx_kl            | 0.00590601 |\n|    clip_fraction        | 0.0282     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.12      |\n|    explained_variance   | 0.00159    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 479        |\n|    n_updates            | 60         |\n|    policy_gradient_loss | -0.00204   |\n|    value_loss           | 784        |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 262         |\n|    ep_rew_mean          | -3.63       |\n| time/                   |             |\n|    fps                  | 1421        |\n|    iterations           | 17          |\n|    time_elapsed         | 196         |\n|    total_timesteps      | 278528      |\n| train/                  |             |\n|    approx_kl            | 0.007029063 |\n|    clip_fraction        | 0.044       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.11       |\n|    explained_variance   | 0.0117      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 275         |\n|    n_updates            | 64          |\n|    policy_gradient_loss | -0.00137    |\n|    value_loss           | 587         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 380          |\n|    ep_rew_mean          | 4.81         |\n| time/                   |              |\n|    fps                  | 1348         |\n|    iterations           | 18           |\n|    time_elapsed         | 218          |\n|    total_timesteps      | 294912       |\n| train/                  |              |\n|    approx_kl            | 0.0072521633 |\n|    clip_fraction        | 0.0347       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.12        |\n|    explained_variance   | -0.00572     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 421          |\n|    n_updates            | 68           |\n|    policy_gradient_loss | -0.00226     |\n|    value_loss           | 675          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 425         |\n|    ep_rew_mean          | 9.11        |\n| time/                   |             |\n|    fps                  | 1297        |\n|    iterations           | 19          |\n|    time_elapsed         | 240         |\n|    total_timesteps      | 311296      |\n| train/                  |             |\n|    approx_kl            | 0.008047722 |\n|    clip_fraction        | 0.0945      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.17       |\n|    explained_variance   | 0.0328      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 162         |\n|    n_updates            | 72          |\n|    policy_gradient_loss | -0.00244    |\n|    value_loss           | 294         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 517          |\n|    ep_rew_mean          | 16.6         |\n| time/                   |              |\n|    fps                  | 1234         |\n|    iterations           | 20           |\n|    time_elapsed         | 265          |\n|    total_timesteps      | 327680       |\n| train/                  |              |\n|    approx_kl            | 0.0042980895 |\n|    clip_fraction        | 0.0191       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.13        |\n|    explained_variance   | 0.249        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 158          |\n|    n_updates            | 76           |\n|    policy_gradient_loss | -0.00142     |\n|    value_loss           | 410          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 581          |\n|    ep_rew_mean          | 22.4         |\n| time/                   |              |\n|    fps                  | 1190         |\n|    iterations           | 21           |\n|    time_elapsed         | 289          |\n|    total_timesteps      | 344064       |\n| train/                  |              |\n|    approx_kl            | 0.0066955434 |\n|    clip_fraction        | 0.0527       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.17        |\n|    explained_variance   | 0.482        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 77.9         |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.0014      |\n|    value_loss           | 227          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 617          |\n|    ep_rew_mean          | 26.1         |\n| time/                   |              |\n|    fps                  | 1146         |\n|    iterations           | 22           |\n|    time_elapsed         | 314          |\n|    total_timesteps      | 360448       |\n| train/                  |              |\n|    approx_kl            | 0.0027773087 |\n|    clip_fraction        | 0.0131       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.16        |\n|    explained_variance   | 0.54         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 214          |\n|    n_updates            | 84           |\n|    policy_gradient_loss | -0.00106     |\n|    value_loss           | 318          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 673          |\n|    ep_rew_mean          | 30.4         |\n| time/                   |              |\n|    fps                  | 1112         |\n|    iterations           | 23           |\n|    time_elapsed         | 338          |\n|    total_timesteps      | 376832       |\n| train/                  |              |\n|    approx_kl            | 0.0050602546 |\n|    clip_fraction        | 0.0383       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.13        |\n|    explained_variance   | 0.686        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 83.8         |\n|    n_updates            | 88           |\n|    policy_gradient_loss | -0.00156     |\n|    value_loss           | 205          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 657         |\n|    ep_rew_mean          | 24.7        |\n| time/                   |             |\n|    fps                  | 1091        |\n|    iterations           | 24          |\n|    time_elapsed         | 360         |\n|    total_timesteps      | 393216      |\n| train/                  |             |\n|    approx_kl            | 0.003694035 |\n|    clip_fraction        | 0.027       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.11       |\n|    explained_variance   | 0.743       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 96.9        |\n|    n_updates            | 92          |\n|    policy_gradient_loss | -0.0015     |\n|    value_loss           | 173         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 673          |\n|    ep_rew_mean          | 28.1         |\n| time/                   |              |\n|    fps                  | 1061         |\n|    iterations           | 25           |\n|    time_elapsed         | 385          |\n|    total_timesteps      | 409600       |\n| train/                  |              |\n|    approx_kl            | 0.0054027243 |\n|    clip_fraction        | 0.0338       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | 0.701        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 256          |\n|    n_updates            | 96           |\n|    policy_gradient_loss | -0.0034      |\n|    value_loss           | 290          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 664          |\n|    ep_rew_mean          | 25           |\n| time/                   |              |\n|    fps                  | 1032         |\n|    iterations           | 26           |\n|    time_elapsed         | 412          |\n|    total_timesteps      | 425984       |\n| train/                  |              |\n|    approx_kl            | 0.0049512256 |\n|    clip_fraction        | 0.0463       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | 0.742        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 124          |\n|    n_updates            | 100          |\n|    policy_gradient_loss | -0.00196     |\n|    value_loss           | 201          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 718         |\n|    ep_rew_mean          | 31.9        |\n| time/                   |             |\n|    fps                  | 1009        |\n|    iterations           | 27          |\n|    time_elapsed         | 438         |\n|    total_timesteps      | 442368      |\n| train/                  |             |\n|    approx_kl            | 0.004277407 |\n|    clip_fraction        | 0.0281      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.06       |\n|    explained_variance   | 0.804       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 31.2        |\n|    n_updates            | 104         |\n|    policy_gradient_loss | -0.00161    |\n|    value_loss           | 115         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 749          |\n|    ep_rew_mean          | 39.6         |\n| time/                   |              |\n|    fps                  | 989          |\n|    iterations           | 28           |\n|    time_elapsed         | 463          |\n|    total_timesteps      | 458752       |\n| train/                  |              |\n|    approx_kl            | 0.0042896066 |\n|    clip_fraction        | 0.0331       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.04        |\n|    explained_variance   | 0.813        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 53.6         |\n|    n_updates            | 108          |\n|    policy_gradient_loss | 0.000157     |\n|    value_loss           | 77.9         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 799          |\n|    ep_rew_mean          | 57.5         |\n| time/                   |              |\n|    fps                  | 973          |\n|    iterations           | 29           |\n|    time_elapsed         | 488          |\n|    total_timesteps      | 475136       |\n| train/                  |              |\n|    approx_kl            | 0.0054298257 |\n|    clip_fraction        | 0.029        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.03        |\n|    explained_variance   | 0.786        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 37.1         |\n|    n_updates            | 112          |\n|    policy_gradient_loss | -0.000913    |\n|    value_loss           | 119          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 827         |\n|    ep_rew_mean          | 64.4        |\n| time/                   |             |\n|    fps                  | 955         |\n|    iterations           | 30          |\n|    time_elapsed         | 514         |\n|    total_timesteps      | 491520      |\n| train/                  |             |\n|    approx_kl            | 0.003981684 |\n|    clip_fraction        | 0.0364      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.04       |\n|    explained_variance   | 0.822       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 133         |\n|    n_updates            | 116         |\n|    policy_gradient_loss | -0.000931   |\n|    value_loss           | 126         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 840         |\n|    ep_rew_mean          | 71.6        |\n| time/                   |             |\n|    fps                  | 940         |\n|    iterations           | 31          |\n|    time_elapsed         | 540         |\n|    total_timesteps      | 507904      |\n| train/                  |             |\n|    approx_kl            | 0.007794007 |\n|    clip_fraction        | 0.0462      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.06       |\n|    explained_variance   | 0.893       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 13.8        |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.00122    |\n|    value_loss           | 68.4        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 819          |\n|    ep_rew_mean          | 74.6         |\n| time/                   |              |\n|    fps                  | 926          |\n|    iterations           | 32           |\n|    time_elapsed         | 565          |\n|    total_timesteps      | 524288       |\n| train/                  |              |\n|    approx_kl            | 0.0032814709 |\n|    clip_fraction        | 0.021        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.04        |\n|    explained_variance   | 0.89         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 9.01         |\n|    n_updates            | 124          |\n|    policy_gradient_loss | -0.000706    |\n|    value_loss           | 73.2         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 834          |\n|    ep_rew_mean          | 76.4         |\n| time/                   |              |\n|    fps                  | 914          |\n|    iterations           | 33           |\n|    time_elapsed         | 591          |\n|    total_timesteps      | 540672       |\n| train/                  |              |\n|    approx_kl            | 0.0038993976 |\n|    clip_fraction        | 0.0222       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.01        |\n|    explained_variance   | 0.887        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 53.5         |\n|    n_updates            | 128          |\n|    policy_gradient_loss | -0.000503    |\n|    value_loss           | 87.2         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 849         |\n|    ep_rew_mean          | 79.1        |\n| time/                   |             |\n|    fps                  | 902         |\n|    iterations           | 34          |\n|    time_elapsed         | 616         |\n|    total_timesteps      | 557056      |\n| train/                  |             |\n|    approx_kl            | 0.005463549 |\n|    clip_fraction        | 0.0538      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.969      |\n|    explained_variance   | 0.903       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 54.8        |\n|    n_updates            | 132         |\n|    policy_gradient_loss | -0.000794   |\n|    value_loss           | 73.8        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 855          |\n|    ep_rew_mean          | 81.4         |\n| time/                   |              |\n|    fps                  | 890          |\n|    iterations           | 35           |\n|    time_elapsed         | 643          |\n|    total_timesteps      | 573440       |\n| train/                  |              |\n|    approx_kl            | 0.0058765924 |\n|    clip_fraction        | 0.0385       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.01        |\n|    explained_variance   | 0.914        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 33.2         |\n|    n_updates            | 136          |\n|    policy_gradient_loss | -0.000363    |\n|    value_loss           | 54           |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 857         |\n|    ep_rew_mean          | 82.9        |\n| time/                   |             |\n|    fps                  | 879         |\n|    iterations           | 36          |\n|    time_elapsed         | 670         |\n|    total_timesteps      | 589824      |\n| train/                  |             |\n|    approx_kl            | 0.004554487 |\n|    clip_fraction        | 0.0322      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.02       |\n|    explained_variance   | 0.914       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.7        |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.00113    |\n|    value_loss           | 77.7        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 873          |\n|    ep_rew_mean          | 85.6         |\n| time/                   |              |\n|    fps                  | 867          |\n|    iterations           | 37           |\n|    time_elapsed         | 698          |\n|    total_timesteps      | 606208       |\n| train/                  |              |\n|    approx_kl            | 0.0068447003 |\n|    clip_fraction        | 0.0437       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.03        |\n|    explained_variance   | 0.924        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 14.7         |\n|    n_updates            | 144          |\n|    policy_gradient_loss | -0.00158     |\n|    value_loss           | 57.4         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 902         |\n|    ep_rew_mean          | 94          |\n| time/                   |             |\n|    fps                  | 858         |\n|    iterations           | 38          |\n|    time_elapsed         | 725         |\n|    total_timesteps      | 622592      |\n| train/                  |             |\n|    approx_kl            | 0.003862715 |\n|    clip_fraction        | 0.0326      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.994      |\n|    explained_variance   | 0.96        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 8.91        |\n|    n_updates            | 148         |\n|    policy_gradient_loss | -0.0015     |\n|    value_loss           | 27.7        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 921          |\n|    ep_rew_mean          | 102          |\n| time/                   |              |\n|    fps                  | 850          |\n|    iterations           | 39           |\n|    time_elapsed         | 751          |\n|    total_timesteps      | 638976       |\n| train/                  |              |\n|    approx_kl            | 0.0058049336 |\n|    clip_fraction        | 0.0428       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.968       |\n|    explained_variance   | 0.95         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 5.52         |\n|    n_updates            | 152          |\n|    policy_gradient_loss | -0.00239     |\n|    value_loss           | 32.1         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 941          |\n|    ep_rew_mean          | 112          |\n| time/                   |              |\n|    fps                  | 844          |\n|    iterations           | 40           |\n|    time_elapsed         | 776          |\n|    total_timesteps      | 655360       |\n| train/                  |              |\n|    approx_kl            | 0.0053523565 |\n|    clip_fraction        | 0.0522       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.971       |\n|    explained_variance   | 0.976        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.88         |\n|    n_updates            | 156          |\n|    policy_gradient_loss | -0.000502    |\n|    value_loss           | 12.9         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 966         |\n|    ep_rew_mean          | 124         |\n| time/                   |             |\n|    fps                  | 837         |\n|    iterations           | 41          |\n|    time_elapsed         | 802         |\n|    total_timesteps      | 671744      |\n| train/                  |             |\n|    approx_kl            | 0.007634852 |\n|    clip_fraction        | 0.0984      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.01       |\n|    explained_variance   | 0.98        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 3.19        |\n|    n_updates            | 160         |\n|    policy_gradient_loss | 0.000333    |\n|    value_loss           | 12.4        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 979          |\n|    ep_rew_mean          | 132          |\n| time/                   |              |\n|    fps                  | 830          |\n|    iterations           | 42           |\n|    time_elapsed         | 828          |\n|    total_timesteps      | 688128       |\n| train/                  |              |\n|    approx_kl            | 0.0058722515 |\n|    clip_fraction        | 0.0202       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.951       |\n|    explained_variance   | 0.973        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.82         |\n|    n_updates            | 164          |\n|    policy_gradient_loss | -0.000852    |\n|    value_loss           | 23.3         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 986          |\n|    ep_rew_mean          | 137          |\n| time/                   |              |\n|    fps                  | 823          |\n|    iterations           | 43           |\n|    time_elapsed         | 855          |\n|    total_timesteps      | 704512       |\n| train/                  |              |\n|    approx_kl            | 0.0052198996 |\n|    clip_fraction        | 0.043        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.954       |\n|    explained_variance   | 0.992        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 3.11         |\n|    n_updates            | 168          |\n|    policy_gradient_loss | 0.000451     |\n|    value_loss           | 7.59         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 986          |\n|    ep_rew_mean          | 141          |\n| time/                   |              |\n|    fps                  | 817          |\n|    iterations           | 44           |\n|    time_elapsed         | 881          |\n|    total_timesteps      | 720896       |\n| train/                  |              |\n|    approx_kl            | 0.0058727437 |\n|    clip_fraction        | 0.0328       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.928       |\n|    explained_variance   | 0.993        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 3.56         |\n|    n_updates            | 172          |\n|    policy_gradient_loss | -0.000456    |\n|    value_loss           | 7.01         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 987         |\n|    ep_rew_mean          | 146         |\n| time/                   |             |\n|    fps                  | 811         |\n|    iterations           | 45          |\n|    time_elapsed         | 908         |\n|    total_timesteps      | 737280      |\n| train/                  |             |\n|    approx_kl            | 0.005593978 |\n|    clip_fraction        | 0.0409      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.904      |\n|    explained_variance   | 0.996       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.7         |\n|    n_updates            | 176         |\n|    policy_gradient_loss | -0.000695   |\n|    value_loss           | 4.54        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 979          |\n|    ep_rew_mean          | 145          |\n| time/                   |              |\n|    fps                  | 808          |\n|    iterations           | 46           |\n|    time_elapsed         | 932          |\n|    total_timesteps      | 753664       |\n| train/                  |              |\n|    approx_kl            | 0.0028393967 |\n|    clip_fraction        | 0.0315       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.883       |\n|    explained_variance   | 0.98         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.54         |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.000108    |\n|    value_loss           | 28           |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 985         |\n|    ep_rew_mean          | 147         |\n| time/                   |             |\n|    fps                  | 804         |\n|    iterations           | 47          |\n|    time_elapsed         | 956         |\n|    total_timesteps      | 770048      |\n| train/                  |             |\n|    approx_kl            | 0.004085016 |\n|    clip_fraction        | 0.0366      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.883      |\n|    explained_variance   | 0.986       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.838       |\n|    n_updates            | 184         |\n|    policy_gradient_loss | -0.000461   |\n|    value_loss           | 15.4        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 985          |\n|    ep_rew_mean          | 148          |\n| time/                   |              |\n|    fps                  | 802          |\n|    iterations           | 48           |\n|    time_elapsed         | 979          |\n|    total_timesteps      | 786432       |\n| train/                  |              |\n|    approx_kl            | 0.0040887194 |\n|    clip_fraction        | 0.0315       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.856       |\n|    explained_variance   | 0.982        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 4.2          |\n|    n_updates            | 188          |\n|    policy_gradient_loss | -0.000429    |\n|    value_loss           | 27.5         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 977          |\n|    ep_rew_mean          | 151          |\n| time/                   |              |\n|    fps                  | 801          |\n|    iterations           | 49           |\n|    time_elapsed         | 1001         |\n|    total_timesteps      | 802816       |\n| train/                  |              |\n|    approx_kl            | 0.0045320652 |\n|    clip_fraction        | 0.0317       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.846       |\n|    explained_variance   | 0.994        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.66         |\n|    n_updates            | 192          |\n|    policy_gradient_loss | -0.000321    |\n|    value_loss           | 5.8          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 977          |\n|    ep_rew_mean          | 153          |\n| time/                   |              |\n|    fps                  | 798          |\n|    iterations           | 50           |\n|    time_elapsed         | 1025         |\n|    total_timesteps      | 819200       |\n| train/                  |              |\n|    approx_kl            | 0.0030960592 |\n|    clip_fraction        | 0.0396       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.907       |\n|    explained_variance   | 0.986        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 19.4         |\n|    n_updates            | 196          |\n|    policy_gradient_loss | -0.000878    |\n|    value_loss           | 15.7         |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 979        |\n|    ep_rew_mean          | 155        |\n| time/                   |            |\n|    fps                  | 795        |\n|    iterations           | 51         |\n|    time_elapsed         | 1050       |\n|    total_timesteps      | 835584     |\n| train/                  |            |\n|    approx_kl            | 0.00450484 |\n|    clip_fraction        | 0.0428     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.915     |\n|    explained_variance   | 0.996      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 1.73       |\n|    n_updates            | 200        |\n|    policy_gradient_loss | 0.00109    |\n|    value_loss           | 4.41       |\n----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 971          |\n|    ep_rew_mean          | 155          |\n| time/                   |              |\n|    fps                  | 793          |\n|    iterations           | 52           |\n|    time_elapsed         | 1074         |\n|    total_timesteps      | 851968       |\n| train/                  |              |\n|    approx_kl            | 0.0060330397 |\n|    clip_fraction        | 0.0402       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.837       |\n|    explained_variance   | 0.984        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.87         |\n|    n_updates            | 204          |\n|    policy_gradient_loss | -0.000341    |\n|    value_loss           | 25.4         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 963          |\n|    ep_rew_mean          | 158          |\n| time/                   |              |\n|    fps                  | 790          |\n|    iterations           | 53           |\n|    time_elapsed         | 1098         |\n|    total_timesteps      | 868352       |\n| train/                  |              |\n|    approx_kl            | 0.0039390847 |\n|    clip_fraction        | 0.0411       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.822       |\n|    explained_variance   | 0.98         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.98         |\n|    n_updates            | 208          |\n|    policy_gradient_loss | -0.000885    |\n|    value_loss           | 28.7         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 936         |\n|    ep_rew_mean          | 164         |\n| time/                   |             |\n|    fps                  | 788         |\n|    iterations           | 54          |\n|    time_elapsed         | 1121        |\n|    total_timesteps      | 884736      |\n| train/                  |             |\n|    approx_kl            | 0.003468316 |\n|    clip_fraction        | 0.0567      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.763      |\n|    explained_variance   | 0.965       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.72        |\n|    n_updates            | 212         |\n|    policy_gradient_loss | -0.000896   |\n|    value_loss           | 63.3        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 877          |\n|    ep_rew_mean          | 180          |\n| time/                   |              |\n|    fps                  | 789          |\n|    iterations           | 55           |\n|    time_elapsed         | 1141         |\n|    total_timesteps      | 901120       |\n| train/                  |              |\n|    approx_kl            | 0.0050258143 |\n|    clip_fraction        | 0.0613       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.693       |\n|    explained_variance   | 0.915        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 75.8         |\n|    n_updates            | 216          |\n|    policy_gradient_loss | -0.00256     |\n|    value_loss           | 142          |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 733        |\n|    ep_rew_mean          | 212        |\n| time/                   |            |\n|    fps                  | 791        |\n|    iterations           | 56         |\n|    time_elapsed         | 1159       |\n|    total_timesteps      | 917504     |\n| train/                  |            |\n|    approx_kl            | 0.00685859 |\n|    clip_fraction        | 0.0663     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.658     |\n|    explained_variance   | 0.86       |\n|    learning_rate        | 0.0003     |\n|    loss                 | 101        |\n|    n_updates            | 220        |\n|    policy_gradient_loss | -0.00339   |\n|    value_loss           | 250        |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 506         |\n|    ep_rew_mean          | 241         |\n| time/                   |             |\n|    fps                  | 793         |\n|    iterations           | 57          |\n|    time_elapsed         | 1176        |\n|    total_timesteps      | 933888      |\n| train/                  |             |\n|    approx_kl            | 0.009260762 |\n|    clip_fraction        | 0.0956      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.701      |\n|    explained_variance   | 0.799       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 238         |\n|    n_updates            | 224         |\n|    policy_gradient_loss | -0.00307    |\n|    value_loss           | 288         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 376         |\n|    ep_rew_mean          | 248         |\n| time/                   |             |\n|    fps                  | 796         |\n|    iterations           | 58          |\n|    time_elapsed         | 1193        |\n|    total_timesteps      | 950272      |\n| train/                  |             |\n|    approx_kl            | 0.007336115 |\n|    clip_fraction        | 0.0702      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.721      |\n|    explained_variance   | 0.793       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 89.6        |\n|    n_updates            | 228         |\n|    policy_gradient_loss | -0.00273    |\n|    value_loss           | 252         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 323         |\n|    ep_rew_mean          | 246         |\n| time/                   |             |\n|    fps                  | 800         |\n|    iterations           | 59          |\n|    time_elapsed         | 1208        |\n|    total_timesteps      | 966656      |\n| train/                  |             |\n|    approx_kl            | 0.008138116 |\n|    clip_fraction        | 0.0541      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.71       |\n|    explained_variance   | 0.738       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.2        |\n|    n_updates            | 232         |\n|    policy_gradient_loss | -0.00199    |\n|    value_loss           | 196         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 303          |\n|    ep_rew_mean          | 265          |\n| time/                   |              |\n|    fps                  | 803          |\n|    iterations           | 60           |\n|    time_elapsed         | 1222         |\n|    total_timesteps      | 983040       |\n| train/                  |              |\n|    approx_kl            | 0.0051652836 |\n|    clip_fraction        | 0.0498       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.723       |\n|    explained_variance   | 0.66         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 63.5         |\n|    n_updates            | 236          |\n|    policy_gradient_loss | -0.0011      |\n|    value_loss           | 289          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 267          |\n| time/                   |              |\n|    fps                  | 808          |\n|    iterations           | 61           |\n|    time_elapsed         | 1236         |\n|    total_timesteps      | 999424       |\n| train/                  |              |\n|    approx_kl            | 0.0038306061 |\n|    clip_fraction        | 0.0365       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.711       |\n|    explained_variance   | 0.855        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 17.5         |\n|    n_updates            | 240          |\n|    policy_gradient_loss | 4.75e-05     |\n|    value_loss           | 46.7         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 290          |\n|    ep_rew_mean          | 262          |\n| time/                   |              |\n|    fps                  | 811          |\n|    iterations           | 62           |\n|    time_elapsed         | 1251         |\n|    total_timesteps      | 1015808      |\n| train/                  |              |\n|    approx_kl            | 0.0037608556 |\n|    clip_fraction        | 0.0374       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.723       |\n|    explained_variance   | 0.827        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 4.77         |\n|    n_updates            | 244          |\n|    policy_gradient_loss | -0.000544    |\n|    value_loss           | 86.3         |\n------------------------------------------\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluate Agent","metadata":{}},{"cell_type":"code","source":"eval_env = Monitor(gym.make(\"LunarLander-v2\"))\nmean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\nprint(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:07:34.964197Z","iopub.execute_input":"2023-07-04T17:07:34.964663Z","iopub.status.idle":"2023-07-04T17:07:38.107009Z","shell.execute_reply.started":"2023-07-04T17:07:34.964629Z","shell.execute_reply":"2023-07-04T17:07:38.105949Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"mean_reward=263.32 +/- 21.354370628936692\n","output_type":"stream"}]},{"cell_type":"code","source":"notebook_login()\n!git config --global credential.helper store","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:09:22.292219Z","iopub.execute_input":"2023-07-04T17:09:22.292680Z","iopub.status.idle":"2023-07-04T17:09:23.450308Z","shell.execute_reply.started":"2023-07-04T17:09:22.292647Z","shell.execute_reply":"2023-07-04T17:09:23.448804Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f9244a62d584450b9f6f3ec6269582b"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Pushing model to hub","metadata":{}},{"cell_type":"code","source":"import gymnasium as gym\n\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nfrom stable_baselines3.common.env_util import make_vec_env\n\nfrom huggingface_sb3 import package_to_hub\n\n# PLACE the variables you've just defined two cells above\n# Define the name of the environment\nenv_id = \"LunarLander-v2\"\n\n# TODO: Define the model architecture we used\nmodel_architecture = \"PPO\"\n\n## Define a repo_id\n## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n## CHANGE WITH YOUR REPO ID\nrepo_id = \"darthPanda/ppo-LunarLander-v1\" # Change with your repo id, you can't push with mine 😄\n\n## Define the commit message\ncommit_message = \"Upload PPO LunarLander-v2 trained agent\"\n\n# Create the evaluation env and set the render_mode=\"rgb_array\"\neval_env = DummyVecEnv([lambda: gym.make(env_id, render_mode=\"rgb_array\")])\n\n# PLACE the package_to_hub function you've just filled here\npackage_to_hub(model=model, # Our trained model\n               model_name=model_name, # The name of our trained model \n               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n               env_id=env_id, # Name of the environment\n               eval_env=eval_env, # Evaluation Environment\n               repo_id=repo_id, \n               is_deterministic=False,\n               commit_message=commit_message)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-04T17:23:05.496497Z","iopub.execute_input":"2023-07-04T17:23:05.497707Z","iopub.status.idle":"2023-07-04T17:23:17.118678Z","shell.execute_reply.started":"2023-07-04T17:23:05.497652Z","shell.execute_reply":"2023-07-04T17:23:17.117485Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"\u001b[38;5;4mℹ This function will save, evaluate, generate a video of your agent,\ncreate a model card and push everything to the hub. It might take up to 1min.\nThis is a work in progress: if you encounter a bug, please open an issue.\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n  warnings.warn(\nException ignored in: <function VecVideoRecorder.__del__ at 0x7aa38421fa30>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_video_recorder.py\", line 113, in __del__\n    self.close_video_recorder()\n  File \"/opt/conda/lib/python3.10/site-packages/stable_baselines3/common/vec_env/vec_video_recorder.py\", line 104, in close_video_recorder\n    self.video_recorder.close()\n  File \"/opt/conda/lib/python3.10/site-packages/gymnasium/wrappers/monitoring/video_recorder.py\", line 161, in close\n    clip.write_videofile(self.path, logger=moviepy_logger)\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n    for i, extra in enumerate(extras):\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/decorators.py\", line 54, in requires_duration\n    return f(clip, *a, **k)\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n    for i, extra in enumerate(extras):\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/decorators.py\", line 135, in use_clip_fps_by_default\n    return f(clip, *new_a, **new_kw)\n  File \"/opt/conda/lib/python3.10/site-packages/decorator.py\", line 232, in fun\n    for i, extra in enumerate(extras):\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/decorators.py\", line 22, in convert_masks_to_RGB\n    return f(clip, *a, **k)\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/video/VideoClip.py\", line 300, in write_videofile\n    ffmpeg_write_video(self, filename, fps, codec,\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_writer.py\", line 213, in ffmpeg_write_video\n    with FFMPEG_VideoWriter(filename, clip.size, fps, codec = codec,\n  File \"/opt/conda/lib/python3.10/site-packages/moviepy/video/io/ffmpeg_writer.py\", line 88, in __init__\n    '-r', '%.02f' % fps,\nTypeError: must be real number, not NoneType\n","output_type":"stream"},{"name":"stdout","text":"Saving video to /tmp/tmpszz8n6x1/-step-0-to-step-1000.mp4\nMoviepy - Building video /tmp/tmpszz8n6x1/-step-0-to-step-1000.mp4.\nMoviepy - Writing video /tmp/tmpszz8n6x1/-step-0-to-step-1000.mp4\n\n\u001b[38;5;1m✘ must be real number, not NoneType\u001b[0m\n\u001b[38;5;1m✘ We are unable to generate a replay of your agent, the package_to_hub\nprocess continues\u001b[0m\n\u001b[38;5;1m✘ Please open an issue at\nhttps://github.com/huggingface/huggingface_sb3/issues\u001b[0m\nMoviepy - Building video /tmp/tmpszz8n6x1/-step-0-to-step-1000.mp4.\nMoviepy - Writing video /tmp/tmpszz8n6x1/-step-0-to-step-1000.mp4\n\n\u001b[38;5;4mℹ Pushing repo darthPanda/ppo-LunarLander-v1 to the Hugging Face\nHub\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8151d8921c724c5d8ed62a1a2eff57a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ppo-LunarLander-v2.zip:   0%|          | 0.00/147k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"061516322d444057a98294b342671602"}},"metadata":{}},{"name":"stdout","text":"\u001b[38;5;4mℹ Your model is pushed to the Hub. You can view your model here:\nhttps://huggingface.co/darthPanda/ppo-LunarLander-v1/tree/main/\u001b[0m\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/darthPanda/ppo-LunarLander-v1/tree/main/'"},"metadata":{}}]}]}